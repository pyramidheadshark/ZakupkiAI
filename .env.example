# --- General Settings ---
LOG_LEVEL="INFO" # Уровень логирования: DEBUG, INFO, WARNING, ERROR

# --- LLM Provider ---
# Выберите провайдера: "local" или "gemini"
LLM_PROVIDER="gemini"

# --- Local LLM Settings (if LLM_PROVIDER="local") ---
MODEL_GGUF_PATH="path/to/your/model.gguf" # Укажите путь к вашей локальной модели
N_GPU_LAYERS=20
N_BATCH=512
N_CTX=4096
# TEMPERATURE_LOCAL=0.5 # Можно задать отдельно для локальной
# MAX_TOKENS_LOCAL=1024 # Можно задать отдельно для локальной

# --- Gemini LLM Settings (if LLM_PROVIDER="gemini") ---
# !! ВАЖНО: Замените на ваш реальный ключ !! Используйте кавычки, если ключ содержит спецсимволы.
GOOGLE_API_KEY="ВАШ_GOOGLE_API_KEY" # ЗАМЕНИТЬ НА ВАШ КЛЮЧ
# Имя модели Gemini (Проверьте доступные модели в документации Google AI)
GEMINI_MODEL_NAME="gemini-2.0-flash"
TAVILY_API_KEY="ВАШ_TAVILY_API_KEY"
# TEMPERATURE_GEMINI=0.7 # Можно задать отдельно для Gemini
# MAX_TOKENS_GEMINI=2048 # Можно задать отдельно для Gemini

# --- Common LLM/Agent Settings ---
TEMPERATURE=0.6 # Общая температура (можно переопределить выше)
MAX_TOKENS=1536 # Общее макс. кол-во токенов (можно переопределить выше)
LLM_VERBOSE=False # Внутреннее логирование LlamaCpp/Gemini (может быть очень многословно)
AGENT_VERBOSE=True # Логирование шагов агента (Мысль/Действие/Наблюдение)
AGENT_MAX_ITERATIONS=7

# --- Embedding Model ---
EMBEDDING_MODEL_NAME="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
EMBEDDING_DEVICE="cpu" # 'cpu' или 'cuda'

# --- Tools Settings ---
VERIFIED_SOURCES_FILE="data/raw/verified_sources.txt"
MAX_SEARCH_RESULTS=3
MAX_PAGE_CHUNKS=3
WEB_LOADER_TIMEOUT=15